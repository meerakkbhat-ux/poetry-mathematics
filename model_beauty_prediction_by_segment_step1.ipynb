{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4744c49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after merge: 10710\n",
      "Participants: 51\n",
      "\n",
      "Rows by taste_cluster:\n",
      "taste_cluster\n",
      "0    2940\n",
      "1    4830\n",
      "2    1050\n",
      "3    1890\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n",
      "TASTE CLUSTER 0\n",
      "======================================================================\n",
      "Rows: 2940\n",
      "Participants in cluster: 14\n",
      "R2   : 0.4560\n",
      "MAE  : 1.2025\n",
      "RMSE : 1.5372\n",
      "\n",
      "Top feature importances:\n",
      "                feature  importance\n",
      "        avg_word_length    0.345808\n",
      "           char_entropy    0.159553\n",
      "         surprise_score    0.129230\n",
      "            order_score    0.123245\n",
      "              num_words    0.045425\n",
      "       line_length_mean    0.043242\n",
      "        syllables_total    0.036323\n",
      "syllables_per_line_mean    0.036290\n",
      "\n",
      "======================================================================\n",
      "TASTE CLUSTER 1\n",
      "======================================================================\n",
      "Rows: 4830\n",
      "Participants in cluster: 23\n",
      "R2   : 0.2331\n",
      "MAE  : 0.8942\n",
      "RMSE : 1.1318\n",
      "\n",
      "Top feature importances:\n",
      "                    feature  importance\n",
      "            avg_word_length    0.360463\n",
      "             surprise_score    0.151110\n",
      "               char_entropy    0.146585\n",
      "                order_score    0.106970\n",
      "            syllables_total    0.044545\n",
      "    syllables_per_line_mean    0.043388\n",
      "syllables_per_line_variance    0.033203\n",
      "                  num_words    0.031269\n",
      "\n",
      "======================================================================\n",
      "TASTE CLUSTER 2\n",
      "======================================================================\n",
      "Rows: 1050\n",
      "Participants in cluster: 5\n",
      "R2   : -0.3051\n",
      "MAE  : 0.9095\n",
      "RMSE : 1.0964\n",
      "\n",
      "Top feature importances:\n",
      "                    feature  importance\n",
      "               char_entropy    0.245910\n",
      "                order_score    0.182352\n",
      "            avg_word_length    0.159022\n",
      "             surprise_score    0.117116\n",
      "               word_entropy    0.061166\n",
      "            syllables_total    0.047528\n",
      "    syllables_per_line_mean    0.045577\n",
      "syllables_per_line_variance    0.044438\n",
      "\n",
      "======================================================================\n",
      "TASTE CLUSTER 3\n",
      "======================================================================\n",
      "Rows: 1890\n",
      "Participants in cluster: 9\n",
      "R2   : -0.0363\n",
      "MAE  : 1.3041\n",
      "RMSE : 1.5725\n",
      "\n",
      "Top feature importances:\n",
      "                    feature  importance\n",
      "               char_entropy    0.215181\n",
      "                order_score    0.171958\n",
      "             surprise_score    0.167086\n",
      "            avg_word_length    0.153154\n",
      "syllables_per_line_variance    0.071124\n",
      "    syllables_per_line_mean    0.043705\n",
      "            syllables_total    0.040523\n",
      "                  num_words    0.037689\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# ---------- Paths ----------\n",
    "BASE_DIR = r\"C:\\PG, IELTS, DOCS\\research paper\\poetry project\"\n",
    "RATINGS_FILE = os.path.join(BASE_DIR, \"data_processed\", \"poetry_features_with_scores_v1.csv\")\n",
    "PARTICIPANT_SEG_FILE = os.path.join(BASE_DIR, \"data_processed\", \"participant_taste_clusters_step1.csv\")\n",
    "\n",
    "\n",
    "def eval_rf_segment(seg_df: pd.DataFrame, feature_cols, target_col=\"aesthetic_appeal\"):\n",
    "    model_df = seg_df[feature_cols + [target_col]].dropna().copy()\n",
    "\n",
    "    X = model_df[feature_cols]\n",
    "    y = model_df[target_col]\n",
    "\n",
    "    # Guard: need enough data and target variation\n",
    "    if len(model_df) < 200 or y.nunique() < 3:\n",
    "        return None, None, None, None\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        min_samples_leaf=2\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    preds = rf.predict(X_test)\n",
    "\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    rmse = math.sqrt(mean_squared_error(y_test, preds))\n",
    "\n",
    "    imp_df = pd.DataFrame({\n",
    "        \"feature\": feature_cols,\n",
    "        \"importance\": rf.feature_importances_\n",
    "    }).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    return r2, mae, rmse, imp_df\n",
    "\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(RATINGS_FILE)\n",
    "    part_seg = pd.read_csv(PARTICIPANT_SEG_FILE)\n",
    "\n",
    "    # Keep only participant_id + cluster label for merge\n",
    "    part_seg = part_seg[[\"participant_id\", \"taste_cluster\"]].drop_duplicates()\n",
    "\n",
    "    merged = df.merge(part_seg, on=\"participant_id\", how=\"left\")\n",
    "\n",
    "    feature_cols = [\n",
    "        \"num_words\",\n",
    "        \"avg_word_length\",\n",
    "        \"line_length_mean\",\n",
    "        \"line_length_variance\",\n",
    "        \"syllables_total\",\n",
    "        \"syllables_per_line_mean\",\n",
    "        \"syllables_per_line_variance\",\n",
    "        \"word_entropy\",\n",
    "        \"char_entropy\",\n",
    "        \"order_score\",\n",
    "        \"surprise_score\",\n",
    "    ]\n",
    "\n",
    "    print(\"Rows after merge:\", len(merged))\n",
    "    print(\"Participants:\", merged[\"participant_id\"].nunique())\n",
    "    print(\"\\nRows by taste_cluster:\")\n",
    "    print(merged[\"taste_cluster\"].value_counts().sort_index())\n",
    "\n",
    "    for cluster_id in sorted(merged[\"taste_cluster\"].dropna().unique()):\n",
    "        seg_df = merged[merged[\"taste_cluster\"] == cluster_id].copy()\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"TASTE CLUSTER {int(cluster_id)}\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Rows: {len(seg_df)}\")\n",
    "        print(f\"Participants in cluster: {seg_df['participant_id'].nunique()}\")\n",
    "\n",
    "        result = eval_rf_segment(seg_df, feature_cols)\n",
    "\n",
    "        if result[0] is None:\n",
    "            print(\"Not enough data or target variation for stable modeling.\")\n",
    "            continue\n",
    "\n",
    "        r2, mae, rmse, imp_df = result\n",
    "        print(f\"R2   : {r2:.4f}\")\n",
    "        print(f\"MAE  : {mae:.4f}\")\n",
    "        print(f\"RMSE : {rmse:.4f}\")\n",
    "\n",
    "        print(\"\\nTop feature importances:\")\n",
    "        print(imp_df.head(8).to_string(index=False))\n",
    "\n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc88ddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cluster 0\n",
    "#The most style-selective readers were also the most mathematically predictable.\n",
    "#they strongly prefer H/S over C\n",
    "#they reward surprise\n",
    "#they appear to use a relatively stable internal rule for beauty\n",
    "\n",
    "## cluster 1\n",
    "#This group is more open and balanced, so their ratings are less driven by a single style rule.\n",
    "#The largest audience segment was moderately predictable: they reward structure and surprise, but with broader tolerance.\n",
    "\n",
    "## cluster 2 \n",
    "#Generalist readers were the hardest to model \n",
    "#because they rated most poems positively, reducing the variance needed for predictive learning\n",
    "#This segment rates almost everything high\n",
    "#has low variance\n",
    "#doesn’t discriminate much between styles So there’s less signal to learn.\n",
    "\n",
    "## cluster 3\n",
    "#Tough critics may rely on deeper semantic or emotional criteria beyond surface structure and entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5faca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
