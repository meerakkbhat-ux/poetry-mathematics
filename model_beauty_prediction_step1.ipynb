{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c555f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows used: 10710\n",
      "Features used: 11\n",
      "Target: aesthetic_appeal\n",
      "\n",
      "=== Linear Regression ===\n",
      "R2   : 0.0930\n",
      "MAE  : 1.2792\n",
      "RMSE : 1.5743\n",
      "\n",
      "Linear Regression coefficients (direction + strength):\n",
      "                    feature   coefficient\n",
      "    syllables_per_line_mean  2.337047e+13\n",
      "                  num_words  5.162115e+12\n",
      "               word_entropy  1.311782e+12\n",
      "               char_entropy -1.883071e-01\n",
      "             surprise_score -1.265036e+12\n",
      "syllables_per_line_variance -4.104203e+12\n",
      "            avg_word_length -4.998130e+12\n",
      "       line_length_variance -5.770799e+12\n",
      "            syllables_total -7.790156e+12\n",
      "           line_length_mean -1.548635e+13\n",
      "                order_score -1.551984e+13\n",
      "\n",
      "=== Random Forest Regressor ===\n",
      "R2   : 0.2169\n",
      "MAE  : 1.1802\n",
      "RMSE : 1.4628\n",
      "\n",
      "Random Forest feature importances:\n",
      "                    feature  importance\n",
      "            avg_word_length    0.340697\n",
      "               char_entropy    0.163255\n",
      "             surprise_score    0.154367\n",
      "                order_score    0.119703\n",
      "    syllables_per_line_mean    0.040698\n",
      "            syllables_total    0.039883\n",
      "syllables_per_line_variance    0.032212\n",
      "           line_length_mean    0.031034\n",
      "                  num_words    0.029867\n",
      "               word_entropy    0.027356\n",
      "       line_length_variance    0.020928\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# ---------- Paths ----------\n",
    "BASE_DIR = r\"C:\\PG, IELTS, DOCS\\research paper\\poetry project\"\n",
    "IN_FILE = os.path.join(BASE_DIR, \"data_processed\", \"poetry_features_with_scores_v1.csv\")\n",
    "\n",
    "\n",
    "def eval_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    rmse = math.sqrt(mean_squared_error(y_test, preds))\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"R2   : {r2:.4f}\")\n",
    "    print(f\"MAE  : {mae:.4f}\")\n",
    "    print(f\"RMSE : {rmse:.4f}\")\n",
    "\n",
    "    return model, preds\n",
    "\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(IN_FILE)\n",
    "\n",
    "    # Features (v1)\n",
    "    feature_cols = [\n",
    "        \"num_words\",\n",
    "        \"avg_word_length\",\n",
    "        \"line_length_mean\",\n",
    "        \"line_length_variance\",\n",
    "        \"syllables_total\",\n",
    "        \"syllables_per_line_mean\",\n",
    "        \"syllables_per_line_variance\",\n",
    "        \"word_entropy\",\n",
    "        \"char_entropy\",\n",
    "        \"order_score\",\n",
    "        \"surprise_score\",\n",
    "    ]\n",
    "\n",
    "    target_col = \"aesthetic_appeal\"\n",
    "\n",
    "    model_df = df[feature_cols + [target_col]].dropna().copy()\n",
    "\n",
    "    X = model_df[feature_cols]\n",
    "    y = model_df[target_col]\n",
    "\n",
    "    print(\"Rows used:\", len(model_df))\n",
    "    print(\"Features used:\", len(feature_cols))\n",
    "    print(\"Target:\", target_col)\n",
    "\n",
    "    # Random split baseline\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # 1) Linear regression baseline\n",
    "    lr = LinearRegression()\n",
    "    lr_model, _ = eval_model(\"Linear Regression\", lr, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Coefficients (interpretability)\n",
    "    coef_df = pd.DataFrame({\n",
    "        \"feature\": feature_cols,\n",
    "        \"coefficient\": lr_model.coef_\n",
    "    }).sort_values(\"coefficient\", ascending=False)\n",
    "\n",
    "    print(\"\\nLinear Regression coefficients (direction + strength):\")\n",
    "    print(coef_df.to_string(index=False))\n",
    "\n",
    "    # 2) Random Forest baseline\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        min_samples_leaf=2\n",
    "    )\n",
    "    rf_model, _ = eval_model(\"Random Forest Regressor\", rf, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Feature importances (non-linear importance)\n",
    "    imp_df = pd.DataFrame({\n",
    "        \"feature\": feature_cols,\n",
    "        \"importance\": rf_model.feature_importances_\n",
    "    }).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    print(\"\\nRandom Forest feature importances:\")\n",
    "    print(imp_df.to_string(index=False))\n",
    "\n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db51df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The linear baseline showed multicollinearity due to engineered composite features and overlapping structural metrics, \n",
    "#so I relied more on the Random Forest for feature importance and treated linear coefficients as a diagnostic baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27d59d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#giant coefficients (like 2.3e+13) are a multicollinearity issue\n",
    "#num_words and line_length_mean are tightly linked (all poems have 3 lines)\n",
    "#syllables_total and syllables_per_line_mean are linked\n",
    "#order_score and surprise_score are built from other features\n",
    "#So Linear Regression struggles to assign clean coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87b81a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
