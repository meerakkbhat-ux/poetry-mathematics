{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29871303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found block files:\n",
      " - Block_1.xlsx\n",
      " - Block_2.xlsx\n",
      " - Block_3.xlsx\n",
      " - Block_4.xlsx\n",
      " - Block_5.xlsx\n",
      " - Block_6.xlsx\n",
      " - Block_7.xlsx\n",
      "Block_1.xlsx -> 30 poems\n",
      "Block_2.xlsx -> 30 poems\n",
      "Block_3.xlsx -> 30 poems\n",
      "Block_4.xlsx -> 30 poems\n",
      "Block_5.xlsx -> 30 poems\n",
      "Block_6.xlsx -> 30 poems\n",
      "Block_7.xlsx -> 30 poems\n",
      "\n",
      "Done!\n",
      "Saved poem lookup to: C:\\PG, IELTS, DOCS\\research paper\\poetry project\\data_processed\\poem_lookup_full.csv\n",
      "Total poems: 210\n",
      "\n",
      "Preview:\n",
      "                                          PoemKeyRaw  \\\n",
      "0  harvest festival\\njars of fig jam\\nfull of gal...   \n",
      "1  nights drawing in—\\nwondering how Dad is\\nin h...   \n",
      "2  a year at most . . . \\nwe pretend to watch \\nt...   \n",
      "3  Mars landing\\ncardboard softens\\nthe subway grate   \n",
      "4   the heft\\nof a cast-iron skillet\\nautumn deepens   \n",
      "\n",
      "                                             PoemKey  \\\n",
      "0  harvest festival jars of fig jam full of galaxies   \n",
      "1  nights drawing in wondering how dad is in his ...   \n",
      "2  a year at most we pretend to watch the humming...   \n",
      "3    mars landing cardboard softens the subway grate   \n",
      "4     the heft of a cast iron skillet autumn deepens   \n",
      "\n",
      "                                                text PoemType    Block  \n",
      "0  harvest festival\\njars of fig jam\\nfull of gal...        H  Block_1  \n",
      "1  nights drawing in—\\nwondering how Dad is\\nin h...        H  Block_1  \n",
      "2  a year at most . . . \\nwe pretend to watch \\nt...        H  Block_1  \n",
      "3  Mars landing\\ncardboard softens\\nthe subway grate        H  Block_1  \n",
      "4   the heft\\nof a cast-iron skillet\\nautumn deepens        H  Block_1  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- Paths ----------\n",
    "BASE_DIR = r\"C:\\PG, IELTS, DOCS\\research paper\\poetry project\"\n",
    "RAW_DIR = os.path.join(BASE_DIR, \"data_raw\")\n",
    "OUT_DIR = os.path.join(BASE_DIR, \"data_processed\")\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "OUTPUT_FILE = os.path.join(OUT_DIR, \"poem_lookup_full.csv\")\n",
    "\n",
    "\n",
    "def normalize_poem_key(first_line: str) -> str:\n",
    "    \"\"\"Make a clean matching key from first line.\"\"\"\n",
    "    key = str(first_line).strip().lower()\n",
    "\n",
    "    # Remove trailing punctuation and extra dots/spaces\n",
    "    key = key.replace(\"…\", \" \")\n",
    "    key = key.replace(\". . .\", \" \")\n",
    "    key = key.replace(\"...\", \" \")\n",
    "    key = key.replace(\"—\", \" \")\n",
    "    key = key.replace(\"-\", \" \")\n",
    "\n",
    "    # Keep letters/numbers/spaces only\n",
    "    key = \"\".join(ch if ch.isalnum() or ch.isspace() else \" \" for ch in key)\n",
    "    key = \" \".join(key.split())  # collapse spaces\n",
    "    return key\n",
    "\n",
    "\n",
    "def parse_block_file(xlsx_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Parse one Block_X.xlsx where poems are line-by-line and poem ends when PoemType exists.\"\"\"\n",
    "    # Read first sheet\n",
    "    df = pd.read_excel(xlsx_path)\n",
    "\n",
    "    # Expecting columns like PoemName, PoemType (but we guard anyway)\n",
    "    col_a = df.columns[0]\n",
    "    col_b = df.columns[1] if len(df.columns) > 1 else None\n",
    "\n",
    "    poems = []\n",
    "    current_lines = []\n",
    "    current_type = None\n",
    "\n",
    "    block_name = os.path.splitext(os.path.basename(xlsx_path))[0]  # e.g., Block_7\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        line_val = row.get(col_a, None)\n",
    "        type_val = row.get(col_b, None) if col_b else None\n",
    "\n",
    "        # Skip fully empty rows\n",
    "        if pd.isna(line_val) and pd.isna(type_val):\n",
    "            continue\n",
    "\n",
    "        # If line exists, add to current poem lines\n",
    "        if not pd.isna(line_val):\n",
    "            line_text = str(line_val).strip()\n",
    "            if line_text:\n",
    "                current_lines.append(line_text)\n",
    "\n",
    "        # If PoemType is present, this row marks END of poem\n",
    "        if not pd.isna(type_val):\n",
    "            current_type = str(type_val).strip()\n",
    "\n",
    "            if current_lines:\n",
    "                first_line = current_lines[0]\n",
    "                full_text = \" \".join(current_lines)\n",
    "\n",
    "                poems.append({\n",
    "                    \"PoemKeyRaw\": first_line,\n",
    "                    \"PoemKey\": normalize_poem_key(first_line),\n",
    "                    \"text\": full_text,\n",
    "                    \"PoemType\": current_type,\n",
    "                    \"Block\": block_name\n",
    "                })\n",
    "\n",
    "            # Reset for next poem\n",
    "            current_lines = []\n",
    "            current_type = None\n",
    "\n",
    "    return pd.DataFrame(poems)\n",
    "\n",
    "\n",
    "def main():\n",
    "    block_files = sorted(glob.glob(os.path.join(RAW_DIR, \"Block_*.xlsx\")))\n",
    "\n",
    "    if not block_files:\n",
    "        print(\"No Block_*.xlsx files found in:\", RAW_DIR)\n",
    "        return\n",
    "\n",
    "    print(\"Found block files:\")\n",
    "    for f in block_files:\n",
    "        print(\" -\", os.path.basename(f))\n",
    "\n",
    "    all_lookup = []\n",
    "    for bf in block_files:\n",
    "        part = parse_block_file(bf)\n",
    "        print(f\"{os.path.basename(bf)} -> {len(part)} poems\")\n",
    "        all_lookup.append(part)\n",
    "\n",
    "    lookup_df = pd.concat(all_lookup, ignore_index=True)\n",
    "\n",
    "    # Drop duplicates by normalized key if any (keep first)\n",
    "    lookup_df = lookup_df.drop_duplicates(subset=[\"PoemKey\"]).reset_index(drop=True)\n",
    "\n",
    "    lookup_df.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "    print(\"\\nDone!\")\n",
    "    print(\"Saved poem lookup to:\", OUTPUT_FILE)\n",
    "    print(\"Total poems:\", len(lookup_df))\n",
    "    print(\"\\nPreview:\")\n",
    "    print(lookup_df.head())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7f745a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
